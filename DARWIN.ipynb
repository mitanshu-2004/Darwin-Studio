{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 1: Environment Setup and Dependency Management**\n",
        "\n",
        "* Core Libraries: We use torch for GPU-accelerated tensor operations and the diffusers library from Hugging Face to manage the Stable Diffusion XL (SDXL) pipelines.\n",
        "\n",
        "* Interface and Processing: gradio is used to build the interactive laboratory environment, while PIL handles image encoding/decoding.\n",
        "\n",
        "* Optimization: The cell includes gc (garbage collection) to manually clear the system RAM, which is vital for maintaining stability on a T4 GPU with limited memory."
      ],
      "metadata": {
        "id": "dZTRTu9OFCUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import gc\n",
        "import numpy as np\n",
        "import uuid\n",
        "import os\n",
        "from dataclasses import dataclass\n",
        "from diffusers import StableDiffusionXLPipeline, AutoPipelineForImage2Image, EulerDiscreteScheduler, AutoencoderKL\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "epJ6ywo278GB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 2: Data Infrastructure (The \"Specimen\" and Database)**\n",
        "Rather than treating images as static files, this cell establishes a custom data structure that treats every generation as a biological entity.\n",
        "\n",
        "* The Specimen Class: This object stores the \"genetic material\" of an image. The most important field is the dna, a 128x128 latent noise vector (tensor) that defines the structural layout of the image. It also tracks the lineage of the specimen, recording its generation number and parent IDs.\n",
        "\n",
        "* **Database**: It maintains the current_generation for active breeding and a full_history to ensure that users can revisit and breed ancestors from any point in the project‚Äôs timeline.\n"
      ],
      "metadata": {
        "id": "STSkK1YYFiNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Specimen:\n",
        "    id: str\n",
        "    filepath: str\n",
        "    dna: torch.Tensor\n",
        "    genetic_prompt: str\n",
        "    current_prompt: str\n",
        "    generation: int\n",
        "    parent_id: str\n",
        "    quality_score: float = 0.0\n",
        "    seed: int = None\n",
        "    timestamp: str = None\n",
        "\n",
        "class LaboratoryDatabase:\n",
        "    def __init__(self):\n",
        "        self.current_generation = []\n",
        "        self.full_history = []\n",
        "        self.temp_dir = \"/tmp/darwin_studio\"\n",
        "        os.makedirs(self.temp_dir, exist_ok=True)\n",
        "\n",
        "    def save_image(self, image, quality=95):\n",
        "        filename = f\"{uuid.uuid4()}.png\"\n",
        "        path = os.path.join(self.temp_dir, filename)\n",
        "        image.save(path, format='PNG', optimize=True, quality=quality)\n",
        "        return path\n",
        "\n",
        "    def add(self, specimen):\n",
        "        specimen.timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        self.current_generation.append(specimen)\n",
        "        self.full_history.append(specimen)\n",
        "\n",
        "    def get_current(self, index):\n",
        "        if 0 <= index < len(self.current_generation):\n",
        "            return self.current_generation[index]\n",
        "        return None\n",
        "\n",
        "    def get_from_history(self, index):\n",
        "        if 0 <= index < len(self.full_history):\n",
        "            return self.full_history[index]\n",
        "        return None\n",
        "\n",
        "    def clear_current(self):\n",
        "        self.current_generation = []\n",
        "\n",
        "    def get_current_gallery(self):\n",
        "        items = []\n",
        "        for i, s in enumerate(self.current_generation):\n",
        "            quality_bar = \"‚ñà\" * int(s.quality_score * 10) if s.quality_score > 0 else \"\"\n",
        "            label = f\"Gen {s.generation} ‚Ä¢ Q:{s.quality_score:.2f} {quality_bar}\\n{s.genetic_prompt[:40]}...\"\n",
        "            items.append((s.filepath, label))\n",
        "        return items\n",
        "\n",
        "    def get_history_gallery(self):\n",
        "        items = []\n",
        "        for i, s in enumerate(self.full_history):\n",
        "            quality_bar = \"‚ñà\" * int(s.quality_score * 10) if s.quality_score > 0 else \"\"\n",
        "            label = f\"#{i+1} | Gen {s.generation} ‚Ä¢ Q:{s.quality_score:.2f}\\n{s.genetic_prompt[:35]}...\"\n",
        "            items.append((s.filepath, label))\n",
        "        return items\n",
        "\n",
        "    def get_generations_grouped(self):\n",
        "        generations = {}\n",
        "        for s in self.full_history:\n",
        "            if s.generation not in generations:\n",
        "                generations[s.generation] = []\n",
        "            generations[s.generation].append(s)\n",
        "        return generations\n",
        "\n",
        "    def get_stats(self):\n",
        "        if not self.current_generation:\n",
        "            return {\n",
        "                \"current\": len(self.current_generation),\n",
        "                \"max_gen\": 0,\n",
        "                \"avg_quality\": 0,\n",
        "                \"best_quality\": 0,\n",
        "                \"total\": len(self.full_history)\n",
        "            }\n",
        "\n",
        "        total = len(self.current_generation)\n",
        "        max_gen = max(s.generation for s in self.current_generation)\n",
        "        avg_quality = sum(s.quality_score for s in self.current_generation) / total if total > 0 else 0\n",
        "        best_quality = max(s.quality_score for s in self.current_generation) if total > 0 else 0\n",
        "\n",
        "        return {\n",
        "            \"current\": total,\n",
        "            \"max_gen\": max_gen,\n",
        "            \"avg_quality\": avg_quality,\n",
        "            \"best_quality\": best_quality,\n",
        "            \"total\": len(self.full_history)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "Pdz7A7_K78c6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 3: Style Presets (Phenotype Mapping)**\n",
        "To simplify the user experience, this cell defines the STYLE_PRESETS.\n",
        "\n",
        "Purpose: While the DNA defines the structure, these presets define the aesthetic expression (e.g., \"Photorealistic,\" \"Cinematic,\" or \"Oil Painting\").\n"
      ],
      "metadata": {
        "id": "ImfCV1IzFnED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "STYLE_PRESETS = {\n",
        "    \"None\": {\"suffix\": \"\", \"negative\": \"\"},\n",
        "    \"Photorealistic\": {\n",
        "        \"suffix\": \", photorealistic, 8k uhd, high detail, sharp focus, professional photography\",\n",
        "        \"negative\": \"ugly, blurry, cartoon, anime, painting, low quality, distorted\"\n",
        "    },\n",
        "    \"Cinematic\": {\n",
        "        \"suffix\": \", cinematic shot, dramatic lighting, film grain, movie still, professional color grading\",\n",
        "        \"negative\": \"amateur, snapshot, blurry, overexposed, low quality\"\n",
        "    },\n",
        "    \"Oil Painting\": {\n",
        "        \"suffix\": \", oil painting, canvas texture, brushstrokes visible, classical art, masterpiece\",\n",
        "        \"negative\": \"photograph, digital art, 3d render, blurry, low quality\"\n",
        "    },\n",
        "    \"Anime\": {\n",
        "        \"suffix\": \", anime style, cel shaded, vibrant colors, manga art, detailed illustration\",\n",
        "        \"negative\": \"realistic, photograph, western cartoon, blurry, low quality\"\n",
        "    },\n",
        "    \"Cyberpunk\": {\n",
        "        \"suffix\": \", cyberpunk aesthetic, neon lights, futuristic, dystopian, high contrast, detailed\",\n",
        "        \"negative\": \"natural, pastoral, vintage, historical, blurry\"\n",
        "    },\n",
        "    \"Fantasy Art\": {\n",
        "        \"suffix\": \", fantasy art, magical atmosphere, ethereal lighting, concept art, highly detailed\",\n",
        "        \"negative\": \"modern, contemporary, realistic photo, blurry\"\n",
        "    },\n",
        "    \"Studio Portrait\": {\n",
        "        \"suffix\": \", professional studio portrait, soft lighting, shallow depth of field, 85mm lens\",\n",
        "        \"negative\": \"full body, landscape, blurry, distorted face, multiple people\"\n",
        "    },\n",
        "    \"Epic Landscape\": {\n",
        "        \"suffix\": \", epic landscape photography, golden hour, dramatic sky, wide angle, 8k\",\n",
        "        \"negative\": \"people, portrait, closeup, blurry, low quality\"\n",
        "    },\n",
        "}\n"
      ],
      "metadata": {
        "id": "UyAA-mbd_6Dc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 4: The Darwin Engine (The Computational Brain)**\n",
        "This cell loads the heavy-duty models and configures the memory optimization settings required to run SDXL on consumer-grade hardware.\n",
        "\n",
        "**Model Choice:** We use `RealVisXL_V4.0_Lightning`. This is a \"distilled\" model, meaning it can produce high-quality photorealistic images in just 4 to 8 steps, rather than the standard 30 to 50.\n",
        "\n",
        "**The VAE Fix:** We utilize the `madebyollin/sdxl-vae-fp16-fix`. Standard SDXL models often crash or produce black images when running in half-precision (FP16). This specialized VAE is fine-tuned to handle FP16 safely, saving massive amounts of VRAM.\n",
        "\n",
        "**Memory Optimizations:**\n",
        "\n",
        "* VAE Slicing: Instead of decoding a large image all at once, the engine processes it in sequential slices to prevent \"Out of Memory\" (OOM) errors.\n",
        "\n",
        "* Attention Slicing: This breaks down the heavy internal calculations of the UNet, trading a small amount of speed for massive stability."
      ],
      "metadata": {
        "id": "eRBmbmMPFqJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DarwinEngine:\n",
        "    def __init__(self):\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"üöÄ Initializing Darwin Studio on {self.device}...\")\n",
        "\n",
        "        if not torch.cuda.is_available():\n",
        "            raise RuntimeError(\"CUDA not available! This app requires GPU.\")\n",
        "\n",
        "        self.cleanup()\n",
        "\n",
        "        vae = AutoencoderKL.from_pretrained(\n",
        "            \"madebyollin/sdxl-vae-fp16-fix\",\n",
        "            torch_dtype=torch.float16\n",
        "        )\n",
        "\n",
        "        self.txt2img = StableDiffusionXLPipeline.from_pretrained(\n",
        "            \"SG161222/RealVisXL_V4.0_Lightning\",\n",
        "            vae=vae,\n",
        "            torch_dtype=torch.float16,\n",
        "            variant=\"fp16\",\n",
        "            use_safetensors=True\n",
        "        )\n",
        "\n",
        "        self.img2img = AutoPipelineForImage2Image.from_pipe(self.txt2img)\n",
        "\n",
        "        conf = self.txt2img.scheduler.config\n",
        "        for pipe in [self.txt2img, self.img2img]:\n",
        "            pipe.scheduler = EulerDiscreteScheduler.from_config(\n",
        "                conf, timestep_spacing=\"trailing\", use_karras_sigmas=True\n",
        "            )\n",
        "\n",
        "        print(\"‚ö° Moving models to GPU...\")\n",
        "        for pipe in [self.txt2img, self.img2img]:\n",
        "            pipe.to(self.device)\n",
        "            pipe.vae.enable_slicing()\n",
        "            pipe.set_progress_bar_config(disable=True)\n",
        "\n",
        "        try:\n",
        "            for pipe in [self.txt2img, self.img2img]:\n",
        "                pipe.enable_xformers_memory_efficient_attention()\n",
        "            print(\"‚úÖ xFormers enabled\")\n",
        "        except:\n",
        "            try:\n",
        "                for pipe in [self.txt2img, self.img2img]:\n",
        "                    pipe.enable_attention_slicing(1)\n",
        "                print(\"‚úÖ Attention slicing enabled\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        print(f\"‚úÖ Engine Ready\")\n",
        "\n",
        "    def cleanup(self):\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "    def generate_dna(self, batch_size=1, seed=None):\n",
        "        if seed is not None:\n",
        "            generator = torch.Generator(device=self.device).manual_seed(seed)\n",
        "            return torch.randn(\n",
        "                (batch_size, 4, 128, 128),\n",
        "                device=self.device,\n",
        "                dtype=torch.float16,\n",
        "                generator=generator\n",
        "            )\n",
        "        else:\n",
        "            return torch.randn(\n",
        "                (batch_size, 4, 128, 128),\n",
        "                device=self.device,\n",
        "                dtype=torch.float16\n",
        "            )\n",
        "\n",
        "    def image_to_dna(self, image):\n",
        "        if isinstance(image, str):\n",
        "            image = Image.open(image).convert(\"RGB\")\n",
        "        else:\n",
        "            image = image.convert(\"RGB\")\n",
        "\n",
        "        image = image.resize((1024, 1024), Image.LANCZOS)\n",
        "\n",
        "        img_array = np.array(image).astype(np.float32) / 255.0\n",
        "        img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0)\n",
        "        img_tensor = (img_tensor * 2.0) - 1.0\n",
        "        img_tensor = img_tensor.to(self.device, dtype=torch.float16)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            latents = self.txt2img.vae.encode(img_tensor).latent_dist.sample()\n",
        "            latents = latents * self.txt2img.vae.config.scaling_factor\n",
        "\n",
        "        return latents\n",
        "\n",
        "    def calculate_quality_score(self, image):\n",
        "        try:\n",
        "            img_array = np.array(image.convert('L'))\n",
        "            laplacian = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]])\n",
        "            from scipy.ndimage import convolve\n",
        "            sharpness = convolve(img_array.astype(float), laplacian).var()\n",
        "            quality = min(sharpness / 1000.0, 10.0) / 10.0\n",
        "            return quality\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "    def render_txt2img(self, dna, prompt, neg_prompt, steps=8, guidance=2.0):\n",
        "        if dna.device != torch.device(self.device):\n",
        "            dna = dna.to(self.device)\n",
        "\n",
        "        if steps not in [4, 6, 8, 10]:\n",
        "            steps = 8\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            (\n",
        "                prompt_embeds,\n",
        "                negative_prompt_embeds,\n",
        "                pooled_prompt_embeds,\n",
        "                negative_pooled_prompt_embeds,\n",
        "            ) = self.txt2img.encode_prompt(\n",
        "                prompt=prompt,\n",
        "                negative_prompt=neg_prompt,\n",
        "                device=self.device,\n",
        "            )\n",
        "\n",
        "            self.txt2img.scheduler.set_timesteps(steps, device=self.device)\n",
        "            timesteps = self.txt2img.scheduler.timesteps\n",
        "\n",
        "            latents = dna * self.txt2img.scheduler.init_noise_sigma\n",
        "\n",
        "            for i, t in enumerate(timesteps):\n",
        "                latent_model_input = torch.cat([latents] * 2) if guidance > 1.0 else latents\n",
        "                latent_model_input = self.txt2img.scheduler.scale_model_input(latent_model_input, t)\n",
        "\n",
        "                noise_pred = self.txt2img.unet(\n",
        "                    latent_model_input,\n",
        "                    t,\n",
        "                    encoder_hidden_states=torch.cat([negative_prompt_embeds, prompt_embeds]) if guidance > 1.0 else prompt_embeds,\n",
        "                    added_cond_kwargs={\n",
        "                        \"text_embeds\": torch.cat([negative_pooled_prompt_embeds, pooled_prompt_embeds]) if guidance > 1.0 else pooled_prompt_embeds,\n",
        "                        \"time_ids\": self.txt2img._get_add_time_ids(\n",
        "                            (1024, 1024), (0, 0), (1024, 1024),\n",
        "                            dtype=prompt_embeds.dtype,\n",
        "                            text_encoder_projection_dim=1280\n",
        "                        ).to(self.device).repeat(2 if guidance > 1.0 else 1, 1),\n",
        "                    },\n",
        "                ).sample\n",
        "\n",
        "                if guidance > 1.0:\n",
        "                    noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
        "                    noise_pred = noise_pred_uncond + guidance * (noise_pred_text - noise_pred_uncond)\n",
        "\n",
        "                latents = self.txt2img.scheduler.step(noise_pred, t, latents).prev_sample\n",
        "\n",
        "            latents = latents / self.txt2img.vae.config.scaling_factor\n",
        "            image = self.txt2img.vae.decode(latents).sample\n",
        "            image = self.txt2img.image_processor.postprocess(image, output_type=\"pil\")[0]\n",
        "\n",
        "        return image\n",
        "\n",
        "    def render_img2img(self, image_input, prompt, neg_prompt, strength, steps=8):\n",
        "        if isinstance(image_input, str):\n",
        "            source_img = Image.open(image_input).convert(\"RGB\")\n",
        "        elif isinstance(image_input, Image.Image):\n",
        "            source_img = image_input.convert(\"RGB\")\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected image_input type: {type(image_input)}\")\n",
        "\n",
        "        source_img = source_img.resize((1024, 1024), Image.LANCZOS)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            img = self.img2img(\n",
        "                prompt=prompt,\n",
        "                negative_prompt=neg_prompt,\n",
        "                image=source_img,\n",
        "                strength=strength,\n",
        "                num_inference_steps=steps,\n",
        "                guidance_scale=2.5,\n",
        "            ).images[0]\n",
        "\n",
        "        return img\n"
      ],
      "metadata": {
        "id": "R1qt6MY7_8on"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 5: Evolutionary Logic**\n",
        "\n",
        "This cell contains the mathematical formulas that drive the biological simulation.\n",
        "\n",
        "1. Mutation (Evolution): This function injects Gaussian\n",
        "noise into a parent‚Äôs DNA. By adjusting the \"mutation rate,\" users can control how much the child differs from the parent. After mixing, we use renormalization‚Äîdividing the tensor by its own standard deviation‚Äîto ensure the resulting image stays sharp and doesn't become a \"gray goo\" of pixels.\n",
        "\n",
        "2. Breeding (Hybridization): When two parents are bred, we use SLERP (Spherical Linear Interpolation). Standard averages (Linear Interpolation) often produce blurry images because they don't follow the \"curve\" of the AI's internal logic. SLERP follows the arc of the hypersphere, ensuring the hybrid child is as sharp as both parents.\n"
      ],
      "metadata": {
        "id": "GJ9DSQWWFvNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mutate_dna(parent_dna, mutation_rate, device, seed=None):\n",
        "    \"\"\"Controlled mutation\"\"\"\n",
        "    if len(parent_dna.shape) == 3:\n",
        "        parent_dna = parent_dna.unsqueeze(0)\n",
        "\n",
        "    if parent_dna.device != torch.device(device):\n",
        "        parent_dna = parent_dna.to(device)\n",
        "\n",
        "    if seed is not None:\n",
        "        generator = torch.Generator(device=device).manual_seed(seed)\n",
        "        noise = torch.randn(\n",
        "            parent_dna.shape,\n",
        "            device=device,\n",
        "            dtype=torch.float16,\n",
        "            generator=generator\n",
        "        )\n",
        "    else:\n",
        "        noise = torch.randn_like(parent_dna, device=device, dtype=torch.float16)\n",
        "\n",
        "    child = (parent_dna * (1.0 - mutation_rate)) + (noise * mutation_rate)\n",
        "\n",
        "    # Preserve variance\n",
        "    parent_std = parent_dna.std()\n",
        "    child_std = child.std()\n",
        "    if child_std > 0:\n",
        "        child = child * (parent_std / child_std)\n",
        "\n",
        "    return child\n",
        "\n",
        "def breed_dna_with_traits(parent1_dna, parent2_dna, parent1_weight, device, seed=None):\n",
        "    if parent1_dna.device != torch.device(device):\n",
        "        parent1_dna = parent1_dna.to(device)\n",
        "    if parent2_dna.device != torch.device(device):\n",
        "        parent2_dna = parent2_dna.to(device)\n",
        "\n",
        "    if len(parent1_dna.shape) == 3:\n",
        "        parent1_dna = parent1_dna.unsqueeze(0)\n",
        "    if len(parent2_dna.shape) == 3:\n",
        "        parent2_dna = parent2_dna.unsqueeze(0)\n",
        "\n",
        "    parent2_weight = 1.0 - parent1_weight\n",
        "\n",
        "    p1_norm = torch.nn.functional.normalize(parent1_dna.flatten(), dim=0)\n",
        "    p2_norm = torch.nn.functional.normalize(parent2_dna.flatten(), dim=0)\n",
        "\n",
        "    dot_product = (p1_norm * p2_norm).sum()\n",
        "    dot_product = torch.clamp(dot_product, -1.0, 1.0)\n",
        "    omega = torch.acos(dot_product)\n",
        "\n",
        "    so = torch.sin(omega)\n",
        "    if so.abs() < 1e-6:\n",
        "        child_flat = parent1_weight * parent1_dna.flatten() + parent2_weight * parent2_dna.flatten()\n",
        "    else:\n",
        "        child_flat = (torch.sin((1.0 - parent1_weight) * omega) / so) * parent1_dna.flatten() + \\\n",
        "                     (torch.sin(parent1_weight * omega) / so) * parent2_dna.flatten()\n",
        "\n",
        "    child = child_flat.reshape(parent1_dna.shape)\n",
        "\n",
        "    p1_mean = parent1_dna.mean()\n",
        "    p1_std = parent1_dna.std()\n",
        "    p2_mean = parent2_dna.mean()\n",
        "    p2_std = parent2_dna.std()\n",
        "\n",
        "    target_mean = parent1_weight * p1_mean + parent2_weight * p2_mean\n",
        "    target_std = parent1_weight * p1_std + parent2_weight * p2_std\n",
        "\n",
        "    child_mean = child.mean()\n",
        "    child_std = child.std()\n",
        "\n",
        "    if child_std > 1e-6:\n",
        "        child = (child - child_mean) / child_std\n",
        "        child = child * target_std + target_mean\n",
        "\n",
        "    if seed is not None:\n",
        "        generator = torch.Generator(device=device).manual_seed(seed)\n",
        "        noise = torch.randn(\n",
        "            child.shape,\n",
        "            device=device,\n",
        "            dtype=torch.float16,\n",
        "            generator=generator\n",
        "        ) * 0.02 * target_std\n",
        "    else:\n",
        "        noise = torch.randn_like(child, device=device, dtype=torch.float16) * 0.02 * target_std\n",
        "\n",
        "    child = child + noise\n",
        "\n",
        "    final_std = child.std()\n",
        "    if final_std > 1e-6:\n",
        "        child = child * (target_std / final_std)\n",
        "\n",
        "    return child\n"
      ],
      "metadata": {
        "id": "fVxoTqx5AA_O"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ir9R4oq5F3-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "engine = DarwinEngine()\n",
        "db = LaboratoryDatabase()\n",
        "\n",
        "def handle_init(prompt, neg_prompt, seed, style_preset, batch_size, quality_mode, progress=gr.Progress()):\n",
        "    \"\"\"Initialize population\"\"\"\n",
        "    try:\n",
        "        db.clear_current()\n",
        "\n",
        "        genetic_blueprint = prompt\n",
        "        full_prompt = prompt\n",
        "        full_neg = neg_prompt\n",
        "\n",
        "        if style_preset != \"None\":\n",
        "            full_prompt = prompt + STYLE_PRESETS[style_preset][\"suffix\"]\n",
        "            full_neg = neg_prompt + \", \" + STYLE_PRESETS[style_preset][\"negative\"]\n",
        "\n",
        "        if quality_mode == \"Ultra\":\n",
        "            full_prompt += \", masterpiece, best quality, sharp focus, highly detailed\"\n",
        "            full_neg += \", blurry, low quality, worst quality, soft focus\"\n",
        "            guidance = 3.0\n",
        "        elif quality_mode == \"High\":\n",
        "            full_prompt += \", high quality, detailed\"\n",
        "            full_neg += \", low quality, blurry\"\n",
        "            guidance = 2.5\n",
        "        else:\n",
        "            guidance = 2.0\n",
        "\n",
        "        s_val = int(seed) if seed else None\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            progress((i/batch_size), desc=f\"üß¨ Generating {i+1}/{batch_size}...\")\n",
        "\n",
        "            current_seed = (s_val + i) if s_val else None\n",
        "            dna = engine.generate_dna(batch_size=1, seed=current_seed)\n",
        "\n",
        "            img = engine.render_txt2img(dna, full_prompt, full_neg, steps=8, guidance=guidance)\n",
        "            path = db.save_image(img)\n",
        "            quality = engine.calculate_quality_score(img)\n",
        "\n",
        "            specimen = Specimen(\n",
        "                id=str(uuid.uuid4()),\n",
        "                filepath=path,\n",
        "                dna=dna,\n",
        "                genetic_prompt=genetic_blueprint,\n",
        "                current_prompt=full_prompt,\n",
        "                generation=1,\n",
        "                parent_id=\"Genesis\",\n",
        "                quality_score=quality,\n",
        "                seed=current_seed\n",
        "            )\n",
        "            db.add(specimen)\n",
        "\n",
        "        engine.cleanup()\n",
        "\n",
        "        timeline_data = get_timeline_gallery()\n",
        "\n",
        "        stats = db.get_stats()\n",
        "        return (\n",
        "            timeline_data,\n",
        "            f\"‚úÖ Genesis complete ‚Ä¢ Generated {batch_size} specimens\",\n",
        "            f\"Total Specimens: **{stats['total']}** | Max Gen: **{stats['max_gen']}** | Best Quality: **{stats['best_quality']:.2f}**\"\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return [], f\"‚ùå Error: {str(e)}\", \"Total: **0**\"\n",
        "\n",
        "def handle_evolve(selected_idx, mutation_rate, num_variants, quality_mode, progress=gr.Progress()):\n",
        "    \"\"\"Evolution from current generation\"\"\"\n",
        "    if selected_idx is None:\n",
        "        timeline = get_timeline_and_display()\n",
        "        return timeline, \"‚ö†Ô∏è Select a specimen\", get_stats_text()\n",
        "\n",
        "    parent = db.get_from_history(selected_idx)\n",
        "    if not parent:\n",
        "        timeline = get_timeline_and_display()\n",
        "        return timeline, \"‚ö†Ô∏è Invalid selection\", get_stats_text()\n",
        "\n",
        "    db.clear_current()\n",
        "\n",
        "    genetic_blueprint = parent.genetic_prompt\n",
        "    render_prompt = genetic_blueprint\n",
        "    neg_prompt = \"ugly, blurry, low quality\"\n",
        "\n",
        "    if quality_mode == \"Ultra\":\n",
        "        render_prompt += \", masterpiece, best quality, sharp focus\"\n",
        "        neg_prompt += \", blurry, low quality, worst quality\"\n",
        "        guidance = 3.0\n",
        "    elif quality_mode == \"High\":\n",
        "        render_prompt += \", high quality, detailed\"\n",
        "        neg_prompt += \", low quality\"\n",
        "        guidance = 2.5\n",
        "    else:\n",
        "        guidance = 2.0\n",
        "\n",
        "    try:\n",
        "        for i in range(num_variants):\n",
        "            progress((i/num_variants), desc=f\"üß¨ Evolving {i+1}/{num_variants}...\")\n",
        "\n",
        "            mutation_seed = hash(parent.id + str(i)) % (2**32)\n",
        "            child_dna = mutate_dna(parent.dna, mutation_rate, engine.device, seed=mutation_seed)\n",
        "\n",
        "            img = engine.render_txt2img(child_dna, render_prompt, neg_prompt, steps=8, guidance=guidance)\n",
        "            path = db.save_image(img)\n",
        "            quality = engine.calculate_quality_score(img)\n",
        "\n",
        "            child = Specimen(\n",
        "                id=str(uuid.uuid4()),\n",
        "                filepath=path,\n",
        "                dna=child_dna,\n",
        "                genetic_prompt=genetic_blueprint,\n",
        "                current_prompt=render_prompt,\n",
        "                generation=parent.generation + 1,\n",
        "                parent_id=parent.id,\n",
        "                quality_score=quality,\n",
        "                seed=mutation_seed\n",
        "            )\n",
        "            db.add(child)\n",
        "\n",
        "        engine.cleanup()\n",
        "        timeline = get_timeline_and_display()\n",
        "        return (\n",
        "            timeline,\n",
        "            f\"‚úÖ Evolution complete ‚Ä¢ Generation {parent.generation + 1}\",\n",
        "            get_stats_text()\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        engine.cleanup()\n",
        "        timeline = get_timeline_and_display()\n",
        "        return timeline, f\"‚ùå Error: {str(e)}\", get_stats_text()\n",
        "\n",
        "def handle_morph(selected_idx, new_prompt, strength, num_variants, quality_mode, progress=gr.Progress()):\n",
        "    \"\"\"Morph from current generation with variants\"\"\"\n",
        "    if selected_idx is None:\n",
        "        timeline = get_timeline_and_display()\n",
        "        return timeline, \"‚ö†Ô∏è Select a specimen\", get_stats_text()\n",
        "\n",
        "    if not new_prompt or new_prompt.strip() == \"\":\n",
        "        timeline = get_timeline_and_display()\n",
        "        return timeline, \"‚ö†Ô∏è Enter morph prompt\", get_stats_text()\n",
        "\n",
        "    parent = db.get_from_history(selected_idx)\n",
        "    if not parent:\n",
        "        timeline = get_timeline_and_display()\n",
        "        return timeline, \"‚ö†Ô∏è Invalid selection\", get_stats_text()\n",
        "\n",
        "    db.clear_current()\n",
        "\n",
        "    new_genetic_blueprint = new_prompt\n",
        "    neg_prompt = \"ugly, blurry, low quality\"\n",
        "\n",
        "    if quality_mode == \"Ultra\":\n",
        "        neg_prompt += \", blurry, low quality, worst quality\"\n",
        "    elif quality_mode == \"High\":\n",
        "        neg_prompt += \", low quality\"\n",
        "\n",
        "    try:\n",
        "        strength_variations = []\n",
        "        for i in range(num_variants):\n",
        "            variation = strength + (i - num_variants/2) * 0.1\n",
        "            variation = max(0.3, min(0.9, variation))\n",
        "            strength_variations.append(variation)\n",
        "\n",
        "        for i, variant_strength in enumerate(strength_variations):\n",
        "            progress((i/num_variants), desc=f\"üé® Morphing {i+1}/{num_variants}...\")\n",
        "\n",
        "            img = engine.render_img2img(parent.filepath, new_prompt, neg_prompt, variant_strength, steps=8)\n",
        "            path = db.save_image(img)\n",
        "            new_dna = engine.image_to_dna(img)\n",
        "            quality = engine.calculate_quality_score(img)\n",
        "\n",
        "            child = Specimen(\n",
        "                id=str(uuid.uuid4()),\n",
        "                filepath=path,\n",
        "                dna=new_dna,\n",
        "                genetic_prompt=new_genetic_blueprint,\n",
        "                current_prompt=new_prompt,\n",
        "                generation=parent.generation + 1,\n",
        "                parent_id=parent.id,\n",
        "                quality_score=quality\n",
        "            )\n",
        "            db.add(child)\n",
        "\n",
        "        engine.cleanup()\n",
        "        timeline = get_timeline_and_display()\n",
        "        return (\n",
        "            timeline,\n",
        "            f\"‚úÖ Morph complete ‚Ä¢ Generation {parent.generation + 1}\",\n",
        "            get_stats_text()\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        engine.cleanup()\n",
        "        timeline = get_timeline_and_display()\n",
        "        return timeline, f\"‚ùå Error: {str(e)}\", get_stats_text()\n",
        "\n",
        "def handle_breed(parent1_idx, parent2_idx, trait1, trait2, blend_ratio, num_variants, quality_mode, progress=gr.Progress()):\n",
        "    if parent1_idx is None or parent2_idx is None:\n",
        "        timeline = get_timeline_and_display()\n",
        "        return timeline, \"‚ö†Ô∏è Select two parents\", get_stats_text()\n",
        "\n",
        "    if parent1_idx == parent2_idx:\n",
        "        timeline = get_timeline_and_display()\n",
        "        return timeline, \"‚ö†Ô∏è Select DIFFERENT parents\", get_stats_text()\n",
        "\n",
        "    parent1 = db.get_from_history(parent1_idx)\n",
        "    parent2 = db.get_from_history(parent2_idx)\n",
        "\n",
        "    if not parent1 or not parent2:\n",
        "        timeline = get_timeline_and_display()\n",
        "        return timeline, \"‚ö†Ô∏è Invalid selection\", get_stats_text()\n",
        "\n",
        "    trait1_text = trait1.strip() if trait1 and trait1.strip() else parent1.genetic_prompt\n",
        "    trait2_text = trait2.strip() if trait2 and trait2.strip() else parent2.genetic_prompt\n",
        "\n",
        "    hybrid_genetic_prompt = f\"{trait1_text}, {trait2_text}\"\n",
        "\n",
        "    neg_prompt = \"ugly, blurry, low quality, distorted, deformed\"\n",
        "    if quality_mode == \"Ultra\":\n",
        "        hybrid_genetic_prompt += \", masterpiece, best quality, sharp focus, highly detailed\"\n",
        "        neg_prompt += \", blurry, soft focus, low quality, worst quality\"\n",
        "        guidance = 3.5\n",
        "    elif quality_mode == \"High\":\n",
        "        hybrid_genetic_prompt += \", high quality, detailed\"\n",
        "        neg_prompt += \", low quality\"\n",
        "        guidance = 3.0\n",
        "    else:\n",
        "        guidance = 2.5\n",
        "\n",
        "    db.clear_current()\n",
        "\n",
        "    try:\n",
        "        blend_variations = []\n",
        "        for i in range(num_variants):\n",
        "            variation = blend_ratio + (i - num_variants/2) * 0.15\n",
        "            variation = max(0.2, min(0.8, variation))\n",
        "            blend_variations.append(variation)\n",
        "\n",
        "        for i, ratio in enumerate(blend_variations):\n",
        "            progress((i/num_variants), desc=f\"üî¨ Breeding offspring {i+1}/{num_variants}...\")\n",
        "\n",
        "            breed_seed = hash(f\"{parent1.id}{parent2.id}{i}\") % (2**32)\n",
        "\n",
        "            child_dna = breed_dna_with_traits(\n",
        "                parent1.dna,\n",
        "                parent2.dna,\n",
        "                ratio,\n",
        "                engine.device,\n",
        "                seed=breed_seed\n",
        "            )\n",
        "\n",
        "            img = engine.render_txt2img(\n",
        "                child_dna,\n",
        "                hybrid_genetic_prompt,\n",
        "                neg_prompt,\n",
        "                steps=8,\n",
        "                guidance=guidance\n",
        "            )\n",
        "\n",
        "            path = db.save_image(img)\n",
        "            quality = engine.calculate_quality_score(img)\n",
        "\n",
        "            child = Specimen(\n",
        "                id=str(uuid.uuid4()),\n",
        "                filepath=path,\n",
        "                dna=child_dna,\n",
        "                genetic_prompt=hybrid_genetic_prompt,\n",
        "                current_prompt=hybrid_genetic_prompt,\n",
        "                generation=max(parent1.generation, parent2.generation) + 1,\n",
        "                parent_id=f\"{parent1.id[:8]}+{parent2.id[:8]}\",\n",
        "                quality_score=quality,\n",
        "                seed=breed_seed\n",
        "            )\n",
        "            db.add(child)\n",
        "\n",
        "        engine.cleanup()\n",
        "        timeline = get_timeline_and_display()\n",
        "        return (\n",
        "            timeline,\n",
        "            f\"‚úÖ Breeding complete ‚Ä¢ Gen {max(parent1.generation, parent2.generation) + 1}\",\n",
        "            get_stats_text()\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        engine.cleanup()\n",
        "        timeline = get_timeline_and_display()\n",
        "        return timeline, f\"‚ùå Error: {str(e)}\", get_stats_text()\n",
        "\n",
        "def get_timeline_and_display():\n",
        "    return get_timeline_gallery()\n",
        "\n",
        "def get_timeline_gallery():\n",
        "    generations = db.get_generations_grouped()\n",
        "    timeline_items = []\n",
        "\n",
        "    for gen_num in sorted(generations.keys()):\n",
        "        for specimen in generations[gen_num]:\n",
        "            label = f\"#{len(timeline_items)+1} | Gen {gen_num}\"\n",
        "            timeline_items.append((specimen.filepath, label))\n",
        "\n",
        "    return timeline_items\n",
        "\n",
        "def get_stats_text():\n",
        "    stats = db.get_stats()\n",
        "    return f\"Total Specimens: **{stats['total']}** | Max Gen: **{stats['max_gen']}** | Best Quality: **{stats['best_quality']:.2f}**\"\n",
        "\n",
        "def handle_show_specimen_details(evt: gr.SelectData):\n",
        "    if evt is None or evt.index >= len(db.full_history):\n",
        "        return \"*Select a specimen to view details*\"\n",
        "\n",
        "    specimen = db.full_history[evt.index]\n",
        "    quality_stars = \"‚òÖ\" * int(specimen.quality_score * 5) if specimen.quality_score > 0 else \"‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ\"\n",
        "\n",
        "    details = f\"\"\"**SPECIMEN #{evt.index + 1}**\n",
        "\n",
        "**Generation:** {specimen.generation}\n",
        "**Parent ID:** {specimen.parent_id}\n",
        "**Quality:** {quality_stars} ({specimen.quality_score:.3f})\n",
        "**Seed:** {specimen.seed if specimen.seed else \"Random\"}\n",
        "**Created:** {specimen.timestamp}\n",
        "\n",
        "**Genetic Blueprint:**\n",
        "_{specimen.genetic_prompt}_\n",
        "\"\"\"\n",
        "    return details\n",
        "\n",
        "def handle_select_for_breed(evt: gr.SelectData, parent1, parent2, mode):\n",
        "    if evt is None:\n",
        "        return parent1, parent2, \"‚ö†Ô∏è Error selecting specimen\"\n",
        "\n",
        "    # Only process if we're in breeding mode\n",
        "    if mode not in [\"A\", \"B\"]:\n",
        "        return parent1, parent2, \"*Click 'SELECT PARENT A' or 'SELECT PARENT B' button first*\"\n",
        "\n",
        "    idx = evt.index\n",
        "\n",
        "    if mode == \"A\":\n",
        "        specimen = db.get_from_history(idx)\n",
        "        if specimen:\n",
        "            return idx, parent2, f\"‚úÖ Parent A selected: Specimen #{idx + 1} (Gen {specimen.generation})\"\n",
        "        return parent1, parent2, \"‚ö†Ô∏è Invalid selection\"\n",
        "    else:  # mode == \"B\"\n",
        "        if parent1 is None:\n",
        "            return parent1, parent2, \"‚ö†Ô∏è Please select Parent A first\"\n",
        "        specimen = db.get_from_history(idx)\n",
        "        if specimen:\n",
        "            return parent1, idx, f\"‚úÖ Ready to breed! Parent A: #{parent1 + 1} √ó Parent B: #{idx + 1}\"\n",
        "        return parent1, parent2, \"‚ö†Ô∏è Invalid selection\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "b1d2ebbfc781436ba28a0f15117d7d83",
            "d7af15d2f0194a9d8b07958cbbf2aa8c",
            "4e9cc8074cfe4abd906e7f13c131076e",
            "f2edb81e27c24ac6b5ed2ea2af9ba2ee",
            "06c70c2b6aa14bdb9248709cb0391719",
            "1a1c6553e2e940b084b9bebee7042e95",
            "4c976e8e41e041e0b29d8c7e57fb5d71",
            "b582900934b34746b50481c31661a166",
            "b4f8cbd0e29f4169ac285c31a22c8b3d",
            "3b27f66a3123476ebbdb578d3b9c3e79",
            "791f965bebb44cc6939e3b7001ef4e64"
          ]
        },
        "id": "hMLlZY9eAFHZ",
        "outputId": "2141c4cf-4c55-48d8-b03b-89f2283ac66d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Initializing Darwin Studio on cuda...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1d2ebbfc781436ba28a0f15117d7d83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö° Moving models to GPU...\n",
            "‚úÖ Attention slicing enabled\n",
            "‚úÖ Engine Ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 5: The Laboratory Interface (Gradio UI)**\n",
        "The final cell designs the web interface, providing a visual environment for selective breeding.\n"
      ],
      "metadata": {
        "id": "BP0GeoZ2GA8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================================\n",
        "# 6. IMPROVED UI WITH BETTER UX\n",
        "# ==========================================\n",
        "css = \"\"\"\n",
        ":root {\n",
        "    --bg: #0a0a0f;\n",
        "    --panel: #13131f;\n",
        "    --accent: #00f2ff;\n",
        "    --accent-dim: #00f2ff33;\n",
        "    --text: #e0e0e0;\n",
        "    --text-dim: #888;\n",
        "    --border: #2a2a35;\n",
        "    --success: #00ff9d;\n",
        "}\n",
        "\n",
        ".gradio-container {\n",
        "    background: var(--bg) !important;\n",
        "    font-family: 'Segoe UI', Roboto, sans-serif !important;\n",
        "}\n",
        "\n",
        ".sidebar {\n",
        "    background: var(--panel) !important;\n",
        "    border-right: 1px solid var(--border) !important;\n",
        "    padding: 20px !important;\n",
        "}\n",
        "\n",
        ".logo {\n",
        "    font-size: 24px !important;\n",
        "    font-weight: 700 !important;\n",
        "    color: var(--accent) !important;\n",
        "    text-align: center !important;\n",
        "    margin-bottom: 20px !important;\n",
        "}\n",
        "\n",
        ".control-group {\n",
        "    background: #00000033 !important;\n",
        "    padding: 15px !important;\n",
        "    border-radius: 8px !important;\n",
        "    border: 1px solid var(--border) !important;\n",
        "    margin-bottom: 15px !important;\n",
        "}\n",
        "\n",
        "button {\n",
        "    width: 100% !important;\n",
        "    background: var(--accent) !important;\n",
        "    color: #000 !important;\n",
        "    border: none !important;\n",
        "    padding: 12px !important;\n",
        "    font-weight: 600 !important;\n",
        "    cursor: pointer !important;\n",
        "    border-radius: 4px !important;\n",
        "    text-transform: uppercase !important;\n",
        "}\n",
        "\n",
        "button:hover {\n",
        "    background: #fff !important;\n",
        "    box-shadow: 0 0 15px var(--accent) !important;\n",
        "}\n",
        "\n",
        "/* Breeding mode cursor indication */\n",
        ".breeding-mode-a {\n",
        "    cursor: crosshair !important;\n",
        "}\n",
        "\n",
        ".breeding-mode-b {\n",
        "    cursor: crosshair !important;\n",
        "}\n",
        "\n",
        ".timeline-container {\n",
        "    background: var(--panel) !important;\n",
        "    padding: 15px !important;\n",
        "    border-radius: 8px !important;\n",
        "    border: 1px solid var(--border) !important;\n",
        "    margin-bottom: 20px !important;\n",
        "}\n",
        "\n",
        ".main-display {\n",
        "    background: var(--bg) !important;\n",
        "    padding: 20px !important;\n",
        "}\n",
        "\n",
        ".status-box {\n",
        "    background: var(--panel) !important;\n",
        "    border-left: 4px solid var(--accent) !important;\n",
        "    padding: 15px !important;\n",
        "    border-radius: 4px !important;\n",
        "    margin: 10px 0 !important;\n",
        "}\n",
        "\n",
        "/* IMPROVED GALLERY LABELS - Better contrast and visibility */\n",
        ".gallery-item {\n",
        "    position: relative !important;\n",
        "}\n",
        "\n",
        ".gallery-item .caption-label {\n",
        "    background: rgba(0, 0, 0, 0.85) !important;\n",
        "    color: #ffffff !important;\n",
        "    padding: 8px 12px !important;\n",
        "    font-size: 13px !important;\n",
        "    font-weight: 600 !important;\n",
        "    border-radius: 4px !important;\n",
        "    text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.8) !important;\n",
        "}\n",
        "\n",
        ".gallery img {\n",
        "    border: 1px solid var(--border) !important;\n",
        "    border-radius: 8px !important;\n",
        "    transition: 0.3s !important;\n",
        "}\n",
        "\n",
        ".gallery img:hover {\n",
        "    border-color: var(--accent) !important;\n",
        "    box-shadow: 0 0 20px var(--accent) !important;\n",
        "}\n",
        "\n",
        "/* Make text visible in gallery captions */\n",
        "div[data-testid=\"block-label\"] {\n",
        "    color: #ffffff !important;\n",
        "}\n",
        "\n",
        ".gr-gallery .caption {\n",
        "    background: rgba(0, 0, 0, 0.9) !important;\n",
        "    color: #ffffff !important;\n",
        "    font-weight: 600 !important;\n",
        "    padding: 6px 10px !important;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(title=\"Darwin Studio\", theme=gr.themes.Base(), css=css) as app:\n",
        "\n",
        "    # States\n",
        "    breed_parent1_state = gr.State(None)\n",
        "    breed_parent2_state = gr.State(None)\n",
        "    breed_mode_state = gr.State(None)  # None, \"A\", or \"B\"\n",
        "    current_selected_state = gr.State(None)\n",
        "\n",
        "    with gr.Row():\n",
        "        # LEFT SIDEBAR\n",
        "        with gr.Column(scale=2, min_width=320, elem_classes=\"sidebar\"):\n",
        "            gr.HTML('<div class=\"logo\">üß¨ DARWIN STUDIO</div>')\n",
        "\n",
        "            # GENESIS\n",
        "            with gr.Group(elem_classes=\"control-group\"):\n",
        "                gr.Markdown(\"### üåü Genesis\")\n",
        "                master_prompt = gr.Textbox(\n",
        "                    label=\"Prompt\",\n",
        "                    value=\"A futuristic robot in a neon-lit city\",\n",
        "                    lines=3\n",
        "                )\n",
        "                style_dropdown = gr.Dropdown(\n",
        "                    choices=list(STYLE_PRESETS.keys()),\n",
        "                    value=\"Cinematic\",\n",
        "                    label=\"Style\"\n",
        "                )\n",
        "                with gr.Row():\n",
        "                    batch_size = gr.Number(label=\"Batch\", value=2, minimum=2, maximum=4, precision=0)\n",
        "                    quality_mode = gr.Dropdown(choices=[\"Normal\", \"High\", \"Ultra\"], value=\"High\", label=\"Quality\")\n",
        "                btn_init = gr.Button(\"üé¨ GENERATE\")\n",
        "\n",
        "            # EVOLVE\n",
        "            with gr.Accordion(\"üß¨ Evolve\", open=False):\n",
        "                with gr.Group(elem_classes=\"control-group\"):\n",
        "                    mutation_slider = gr.Slider(0.1, 0.9, value=0.35, step=0.05, label=\"Mutation\")\n",
        "                    evolve_variants = gr.Number(label=\"Variants\", value=3, minimum=1, maximum=6, precision=0)\n",
        "                    btn_evolve = gr.Button(\"EVOLVE\")\n",
        "\n",
        "            # MORPH\n",
        "            with gr.Accordion(\"üé® Morph\", open=False):\n",
        "                with gr.Group(elem_classes=\"control-group\"):\n",
        "                    morph_prompt = gr.Textbox(label=\"New Concept\", lines=3)\n",
        "                    strength_slider = gr.Slider(0.1, 0.9, value=0.65, step=0.05, label=\"Strength\")\n",
        "                    morph_variants = gr.Number(label=\"Variants\", value=3, minimum=1, maximum=6, precision=0)\n",
        "                    btn_morph = gr.Button(\"MORPH\")\n",
        "\n",
        "            # BREED\n",
        "            with gr.Accordion(\"üî¨ Breed\", open=False):\n",
        "                with gr.Group(elem_classes=\"control-group\"):\n",
        "                    gr.Markdown(\"**Step 1:** Click button, then click a specimen in timeline\")\n",
        "                    btn_select_a = gr.Button(\"üìå SELECT PARENT A\", variant=\"secondary\")\n",
        "\n",
        "                    gr.Markdown(\"**Step 2:** Click button, then click another specimen\")\n",
        "                    btn_select_b = gr.Button(\"üìå SELECT PARENT B\", variant=\"secondary\")\n",
        "\n",
        "                    breed_status = gr.Markdown(\"*No parents selected*\")\n",
        "\n",
        "                    breed_trait1 = gr.Textbox(label=\"Traits from Parent A (optional)\", lines=2)\n",
        "                    breed_trait2 = gr.Textbox(label=\"Traits from Parent B (optional)\", lines=2)\n",
        "                    blend_slider = gr.Slider(0.3, 0.7, value=0.5, step=0.05, label=\"DNA Balance (A ‚Üê ‚Üí B)\")\n",
        "                    breed_variants = gr.Number(label=\"Variants\", value=4, minimum=2, maximum=8, precision=0)\n",
        "                    btn_breed = gr.Button(\"üî¨ BREED\")\n",
        "\n",
        "            status_box = gr.Markdown(\"**Status:** Ready\", elem_classes=\"status-box\")\n",
        "\n",
        "        # RIGHT MAIN AREA\n",
        "        with gr.Column(scale=5, elem_classes=\"main-display\"):\n",
        "            stats_display = gr.Markdown(\"Total: **0** | Max Gen: **0** | Best: **0.00**\")\n",
        "\n",
        "            gr.Markdown(\"### üìä Evolution Timeline\")\n",
        "            gr.Markdown(\"*All generations - Click any specimen to view details*\")\n",
        "\n",
        "            # Main timeline gallery\n",
        "            timeline_gallery = gr.Gallery(\n",
        "                label=\"Timeline\",\n",
        "                columns=6,\n",
        "                rows=3,\n",
        "                height=600,\n",
        "                object_fit=\"cover\",\n",
        "                show_label=False,\n",
        "                allow_preview=True,\n",
        "                preview=True\n",
        "            )\n",
        "\n",
        "            # Details panel\n",
        "            specimen_details = gr.Markdown(\"*Click a specimen to view details*\", elem_classes=\"status-box\")\n",
        "\n",
        "    # EVENT HANDLERS\n",
        "\n",
        "    # Genesis\n",
        "    btn_init.click(\n",
        "        handle_init,\n",
        "        [master_prompt, gr.State(\"ugly, blurry, low quality\"), gr.State(None), style_dropdown, batch_size, quality_mode],\n",
        "        [timeline_gallery, status_box, stats_display]\n",
        "    )\n",
        "\n",
        "    # Timeline selection shows details\n",
        "    timeline_gallery.select(\n",
        "        handle_show_specimen_details,\n",
        "        None,\n",
        "        specimen_details\n",
        "    )\n",
        "\n",
        "    selected_specimen_state = gr.State(None)\n",
        "\n",
        "    def on_timeline_click_for_operation(evt: gr.SelectData, current_mode):\n",
        "        \"\"\"Store selected specimen index for operations - only if NOT in breeding mode\"\"\"\n",
        "        if evt is None:\n",
        "            return None\n",
        "        if current_mode in [\"A\", \"B\"]:\n",
        "            return None\n",
        "        return evt.index\n",
        "\n",
        "    timeline_gallery.select(\n",
        "        on_timeline_click_for_operation,\n",
        "        breed_mode_state,\n",
        "        selected_specimen_state\n",
        "    )\n",
        "\n",
        "    # Evolve\n",
        "    btn_evolve.click(\n",
        "        handle_evolve,\n",
        "        [selected_specimen_state, mutation_slider, evolve_variants, quality_mode],\n",
        "        [timeline_gallery, status_box, stats_display]\n",
        "    )\n",
        "\n",
        "    # Morph\n",
        "    btn_morph.click(\n",
        "        handle_morph,\n",
        "        [selected_specimen_state, morph_prompt, strength_slider, morph_variants, quality_mode],\n",
        "        [timeline_gallery, status_box, stats_display]\n",
        "    )\n",
        "\n",
        "    def activate_parent_a_mode():\n",
        "        return \"A\", \"*üéØ BREEDING MODE: Click a specimen in the timeline to select Parent A*\"\n",
        "\n",
        "    def activate_parent_b_mode():\n",
        "        return \"B\", \"*üéØ BREEDING MODE: Click a specimen in the timeline to select Parent B*\"\n",
        "\n",
        "    btn_select_a.click(\n",
        "        activate_parent_a_mode,\n",
        "        None,\n",
        "        [breed_mode_state, breed_status]\n",
        "    )\n",
        "\n",
        "    btn_select_b.click(\n",
        "        activate_parent_b_mode,\n",
        "        None,\n",
        "        [breed_mode_state, breed_status]\n",
        "    )\n",
        "\n",
        "    timeline_gallery.select(\n",
        "        handle_select_for_breed,\n",
        "        [breed_parent1_state, breed_parent2_state, breed_mode_state],\n",
        "        [breed_parent1_state, breed_parent2_state, breed_status]\n",
        "    ).then(\n",
        "        lambda: None,\n",
        "        None,\n",
        "        breed_mode_state\n",
        "    )\n",
        "\n",
        "    btn_breed.click(\n",
        "        handle_breed,\n",
        "        [breed_parent1_state, breed_parent2_state, breed_trait1, breed_trait2, blend_slider, breed_variants, quality_mode],\n",
        "        [timeline_gallery, status_box, stats_display]\n",
        "    )\n"
      ],
      "metadata": {
        "id": "vVGdZpSJALcY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.queue(max_size=20)\n",
        "    app.launch(share=True, debug=True, server_port=7870)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "LkOTLrlbAQtZ",
        "outputId": "b7a0b2dc-ead5-403d-8399-4a2fdab0078f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://68bb83df16441d6012.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://68bb83df16441d6012.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VRDSNbpxAixp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b1d2ebbfc781436ba28a0f15117d7d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7af15d2f0194a9d8b07958cbbf2aa8c",
              "IPY_MODEL_4e9cc8074cfe4abd906e7f13c131076e",
              "IPY_MODEL_f2edb81e27c24ac6b5ed2ea2af9ba2ee"
            ],
            "layout": "IPY_MODEL_06c70c2b6aa14bdb9248709cb0391719"
          }
        },
        "d7af15d2f0194a9d8b07958cbbf2aa8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a1c6553e2e940b084b9bebee7042e95",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4c976e8e41e041e0b29d8c7e57fb5d71",
            "value": "Loading‚Äápipeline‚Äácomponents...:‚Äá100%"
          }
        },
        "4e9cc8074cfe4abd906e7f13c131076e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b582900934b34746b50481c31661a166",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4f8cbd0e29f4169ac285c31a22c8b3d",
            "value": 7
          }
        },
        "f2edb81e27c24ac6b5ed2ea2af9ba2ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b27f66a3123476ebbdb578d3b9c3e79",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_791f965bebb44cc6939e3b7001ef4e64",
            "value": "‚Äá7/7‚Äá[00:01&lt;00:00,‚Äá‚Äá3.24it/s]"
          }
        },
        "06c70c2b6aa14bdb9248709cb0391719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a1c6553e2e940b084b9bebee7042e95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c976e8e41e041e0b29d8c7e57fb5d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b582900934b34746b50481c31661a166": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4f8cbd0e29f4169ac285c31a22c8b3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b27f66a3123476ebbdb578d3b9c3e79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "791f965bebb44cc6939e3b7001ef4e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}